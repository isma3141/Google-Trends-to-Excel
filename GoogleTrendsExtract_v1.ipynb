{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "startTime = time.time()\n",
    "pytrend = TrendReq(hl='es-SV', tz=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrendReq(TrendReq):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def interest_by_region(self, resolution='COUNTRY', inc_low_vol=False,\n",
    "                           inc_geo_code=False):\n",
    "        \"\"\"Request data from Google's Interest by Region section and return a dataframe\"\"\"\n",
    "\n",
    "        # Make the request\n",
    "        region_payload = dict()\n",
    "\n",
    "        if self.geo == '': \n",
    "            self.interest_by_region_widget['request']['resolution'] = resolution \n",
    "        elif self.geo == 'SV' and resolution in ['CITY', 'REGION']: \n",
    "            self.interest_by_region_widget['request']['resolution'] = resolution        \n",
    "\n",
    "        self.interest_by_region_widget['request'][\n",
    "            'includeLowSearchVolumeGeos'] = inc_low_vol\n",
    "\n",
    "        # Convert to string as requests will mangle\n",
    "        region_payload['req'] = json.dumps(\n",
    "            self.interest_by_region_widget['request'])\n",
    "        region_payload['token'] = self.interest_by_region_widget['token']\n",
    "        region_payload['tz'] = self.tz\n",
    "\n",
    "        # Parse returned json\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.INTEREST_BY_REGION_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "            params=region_payload,\n",
    "        )\n",
    "        df = pd.DataFrame(req_json['default']['geoMapData'])\n",
    "        if (df.empty):\n",
    "            return df\n",
    "\n",
    "        # Rename the column with the search keyword\n",
    "        df = df[['geoName', 'coordinates', 'value']].set_index(['geoName']).sort_index()\n",
    "      \n",
    "        # Split list columns into seperate ones\n",
    "        result_df = df.copy()\n",
    "        result_df = df['value'].apply(lambda x: pd.Series(\n",
    "            str(x).replace('[', '').replace(']', '').split(',')))\n",
    "        result_df1 = df['coordinates'].apply(lambda x: pd.Series(\n",
    "            str(x).replace('[', '').replace(']', '').replace(\"{'lat':\", '').replace('}', '').replace(\"'lng':\", '').split(',')))\n",
    "        if inc_geo_code:\n",
    "            result_df['geoCode'] = df['geoCode']\n",
    "            \n",
    "        # Rename each column with its search term    \n",
    "        for idx, kw in enumerate(self.kw_list):\n",
    "            result_df[kw] = result_df[idx].astype('int')\n",
    "            del result_df[idx]\n",
    "        result_final = pd.merge(result_df, result_df1, on=\"geoName\")\n",
    "        \n",
    "        # Reset index and rename columns\n",
    "        result_final1 = result_final.copy()\n",
    "        result_final1.reset_index(inplace=True)\n",
    "        result_final1.rename(columns={\"geoName\": \"Ciudad\", 0:\"Latitud\", 1: \"Longitud\"}, inplace=True)\n",
    "        \n",
    "        \n",
    "        for i in ['Latitud','Longitud']:\n",
    "            result_final1[i] = result_final1[i].astype(np.float64)\n",
    "            \n",
    "        return result_final1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel_writer(data_frame, *, sheet_name='Sheet1',table_name='IOT'):\n",
    "    data_frame.to_excel(writer, sheet_name=sheet_name, startrow=1, header=False, index=False)\n",
    "    # Get the xlsxwriter workbook and worksheet objects.\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "    # Get the dimensions of the dataframe.\n",
    "    (max_row, max_col) = data_frame.shape\n",
    "\n",
    "    # Create a list of column headers, to use in add_table().\n",
    "    column_settings = [{'header': column} for column in data_frame.columns]\n",
    "\n",
    "    # Add the Excel table structure. Pandas will add the data.\n",
    "    worksheet.add_table(0, 0, max_row, max_col - 1, {'columns': column_settings,'name': table_name})\n",
    "\n",
    "    # Make the columns wider for clarity.\n",
    "    worksheet.set_column(0, max_col - 1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a list of keywords for searching on Trends and define the timeframe\n",
    "keywords = ['asamblea']\n",
    "timeframe = '2020-05-14 2021-05-14'\n",
    "dataset = []\n",
    "related = []\n",
    "for x in range(0,len(keywords)):\n",
    "     keywords1 = [keywords[x]]\n",
    "     pytrend.build_payload(\n",
    "     kw_list=keywords1,\n",
    "     cat=0,\n",
    "     timeframe=timeframe,   \n",
    "     geo='SV')\n",
    "     data = pytrend.interest_over_time()\n",
    "     related.append(pytrend.related_queries() )  \n",
    "     if not data.empty:\n",
    "          data = data.drop(labels=['isPartial'],axis='columns')\n",
    "          dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(dataset, axis=1)\n",
    "marca_names = list(result.columns.values)\n",
    "df_marca = pd.DataFrame(marca_names,columns =['marca'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the date format and reset the index\n",
    "result.index = result.index.strftime('%d/%m/%Y')\n",
    "result.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpivot the result dataframe, sort and rename the column date\n",
    "df_unpivoted = result.melt(id_vars=['date'], var_name='marca', value_name='valor')\n",
    "df_unpivoted.sort_values(by=['date'], inplace = True)\n",
    "df_unpivoted.rename(columns={\"date\": \"Semana\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get the name of all the search keywords and create a dataframe based on top and rising terms \n",
    "indexes =[index for index, value in enumerate(marca_names)]\n",
    "dict1 = dict(zip(marca_names, indexes))\n",
    "listDataframes = []\n",
    "for k,v in dict1.items():\n",
    "    df_marca_name = pd.DataFrame({'Name': [k for i in range(len(related[v][k]['top']))]})\n",
    "    df_marca_rising = related[v][k]['rising']\n",
    "    df_marca_rising.drop(columns=['value'], inplace=True)\n",
    "    df_marca_rising = df_marca_rising.assign(N=[x for x in range(1,len(df_marca_rising)+1)])\n",
    "    df_marca_merge = pd.concat([df_marca_name,df_marca_rising],ignore_index=True, axis=1)\n",
    "    df_marca_top = related[v][k]['top']\n",
    "    df_merge_total = pd.merge(df_marca_merge,df_marca_top,left_index=True, right_index=True)\n",
    "    df_merge_total = df_merge_total.rename(columns={\"query\": \"TOP\", 0:\"marca\", 1:\"RISING\", 2: \"N\", \"value\":\"%\"})\n",
    "    listDataframes.append(df_merge_total)\n",
    "df_related_queries = pd.concat(listDataframes).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Generate a new object based on MyTrendReq class\n",
    "pytrend_geo = MyTrendReq()\n",
    "pytrend_geo.build_payload(kw_list=keywords, geo='SV', timeframe=timeframe)  \n",
    "df = pytrend_geo.interest_by_region(resolution='CITY', inc_low_vol=True, inc_geo_code=False)\n",
    "df_unpivoted_geo = df.melt(id_vars=['Ciudad','Latitud','Longitud'], var_name='marca', value_name='valor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Invoke the excelWriter engine\n",
    "writer = pd.ExcelWriter('pandas_table.xlsx', engine='xlsxwriter',date_format='dd mm yyyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Call the excel_writer function\n",
    "excel_writer(df_unpivoted)\n",
    "excel_writer(df_marca,sheet_name='Sheet2',table_name='marca')\n",
    "excel_writer(df_related_queries,sheet_name= 'TOP_RISING',table_name='TOP_RISING')\n",
    "excel_writer(df_unpivoted_geo,sheet_name= 'GEO',table_name='GEO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
